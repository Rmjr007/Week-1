# -*- coding: utf-8 -*-
"""Green Policy Simulator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nkHKQFGFHvHMKBV2pIIkJnwpfVx_0WIr
"""

# Install dependencies
!pip install streamlit pyngrok pandas numpy scikit-learn joblib plotly prophet -q

# Upload your dataset
from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv("ev_adoption_dataset_clean.csv")
df.head()

# Clean data and train model
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib, os

# Drop duplicates and fill missing
df = df.drop_duplicates()
df = df.fillna(df.median(numeric_only=True))
df = df.dropna()

# Encode categorical
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))

# Define target and features
target = "avg_cost_ev"   # adjust if your datasetâ€™s column name differs
X = df.drop(columns=[target])
y = df[target]

# Split, scale, and train
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)
y_pred = model.predict(X_test_scaled)

print("RÂ²:", r2_score(y_test, y_pred))
print("MAE:", mean_absolute_error(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

# Save model and scaler
os.makedirs("models", exist_ok=True)
joblib.dump(model, "models/ev_price_model.pkl")
joblib.dump(scaler, "models/scaler.pkl")

# Commented out IPython magic to ensure Python compatibility.
# # Create streamlit app
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import joblib
# 
# model = joblib.load("models/ev_price_model.pkl")
# scaler = joblib.load("models/scaler.pkl")
# 
# st.set_page_config(page_title="EV Price Predictor âš¡")
# 
# st.title("âš¡ Electric Vehicle Price Predictor")
# st.markdown("Enter the EV specifications below:")
# 
# # Assuming the order of features in X_train is consistent
# # You can print X_train.columns to verify the exact names and order
# # For now, I will use the column names from the original dataframe `df` used for training
# # You might need to adjust these based on your actual X_train columns after feature engineering
# # For example, if 'country' and 'year' were included and one-hot encoded.
# # Let's use a simplified approach assuming the input features to the model are just the ones used in the app
# # If you did more complex feature engineering, you'll need to adjust this accordingly.
# 
# # Based on the previous code, X was created by dropping 'avg_cost_ev' from df.
# # So the columns in X (and thus X_train and X_test) are the remaining columns in df.
# # Let's get the column names from the original df, excluding the target, and map them to the input fields.
# 
# # Get the feature names used during training
# # Assuming X_train.columns contains the names of features the model expects
# # If you have done more complex preprocessing that changes column names (e.g., one-hot encoding)
# # you would need to adjust this part to match the exact column names expected by the scaler and model.
# # For this example, let's assume the input features to the model are a subset of the original df columns
# # that correspond to the input fields in the Streamlit app.
# 
# # Let's explicitly define the expected feature names based on the original df columns
# # and map them to the input fields in the Streamlit app.
# 
# # Based on the input fields in the Streamlit app, it seems the intended features are related to EV specs.
# # However, the model was trained on all columns except 'avg_cost_ev'.
# # We need to ensure the input data to the model has the same columns in the same order as X_train.
# 
# # Let's inspect the columns of X_train again to be sure.
# # From the variable inspection, X_train has the following columns:
# # 'country', 'year', 'total_vehicles_registered', 'ev_vehicles_registered',
# # 'ev_percentage_share', 'charging_stations_count', 'avg_cost_gasoline_vehicle',
# # 'gov_incentive_amount', 'co2_emissions_per_vehicle', 'fuel_price_per_liter',
# # 'electricity_price_per_kwh'
# 
# # The Streamlit app currently has inputs for:
# # "Battery Capacity (kWh)", "Top Speed (km/h)", "Range (km)", "Efficiency (Wh/km)", "Number of Seats"
# # These do not directly map to the features the model was trained on.
# 
# # To fix this, we need to either:
# # 1. Retrain the model using only the features that the Streamlit app collects as input.
# # 2. Modify the Streamlit app to collect inputs for all features the model was trained on.
# 
# # Given the current setup, it's likely the intention was to train the model on all available features
# # and the Streamlit app needs to be updated to collect inputs for all of them.
# 
# # Let's modify the Streamlit app to include input fields for all features in X_train.
# 
# # Define input fields for all features in X_train
# # We'll need appropriate input types and labels for each.
# # This is a placeholder and you might need to adjust the input types and ranges
# # based on the nature of each feature.
# 
# st.header("Vehicle and Market Information")
# 
# country = st.number_input("Country (Encoded)", value=9) # Assuming 9 corresponds to a country, adjust as needed
# year = st.number_input("Year", min_value=2015, max_value=2023, value=2023)
# total_vehicles_registered = st.number_input("Total Vehicles Registered", value=20000000)
# ev_vehicles_registered = st.number_input("EV Vehicles Registered", value=100000)
# ev_percentage_share = st.number_input("EV Percentage Share", value=0.5)
# charging_stations_count = st.number_input("Charging Stations Count", value=10000)
# avg_cost_gasoline_vehicle = st.number_input("Average Cost of Gasoline Vehicle", value=30000.0)
# gov_incentive_amount = st.number_input("Government Incentive Amount", value=5000)
# co2_emissions_per_vehicle = st.number_input("CO2 Emissions per Vehicle", value=150.0)
# fuel_price_per_liter = st.number_input("Fuel Price per Liter", value=1.5)
# electricity_price_per_kwh = st.number_input("Electricity Price per kWh", value=0.2)
# 
# 
# input_data = pd.DataFrame({
#     "country": [country],
#     "year": [year],
#     "total_vehicles_registered": [total_vehicles_registered],
#     "ev_vehicles_registered": [ev_vehicles_registered],
#     "ev_percentage_share": [ev_percentage_share],
#     "charging_stations_count": [charging_stations_count],
#     "avg_cost_gasoline_vehicle": [avg_cost_gasoline_vehicle],
#     "gov_incentive_amount": [gov_incentive_amount],
#     "co2_emissions_per_vehicle": [co2_emissions_per_vehicle],
#     "fuel_price_per_liter": [fuel_price_per_liter],
#     "electricity_price_per_kwh": [electricity_price_per_kwh]
# })
# 
# # Ensure the columns are in the same order as X_train
# # This is crucial for the scaler and the model
# # Let's get the columns from the original X_train for correct ordering
# # We can't directly access X_train here, but we know its columns from the previous execution.
# # The columns are: 'country', 'year', 'total_vehicles_registered', 'ev_vehicles_registered', 'ev_percentage_share', 'charging_stations_count', 'avg_cost_gasoline_vehicle', 'gov_incentive_amount', 'co2_emissions_per_vehicle', 'fuel_price_per_liter', 'electricity_price_per_kwh'
# # Let's explicitly reindex the input_data DataFrame to match this order.
# expected_columns = ['country', 'year', 'total_vehicles_registered', 'ev_vehicles_registered',
#                     'ev_percentage_share', 'charging_stations_count', 'avg_cost_gasoline_vehicle',
#                     'gov_incentive_amount', 'co2_emissions_per_vehicle', 'fuel_price_per_liter',
#                     'electricity_price_per_kwh']
# 
# input_data = input_data.reindex(columns=expected_columns)
# 
# 
# scaled = scaler.transform(input_data)
# if st.button("ğŸ”® Predict Price"):
#     pred = model.predict(scaled)[0]
#     st.success(f"Estimated Price: ${pred:,.2f}")
#     st.balloons()

# Run Streamlit through ngrok
!pip install pyngrok -q
from pyngrok import ngrok

# Replace the token below with your own from https://dashboard.ngrok.com/get-started/your-authtoken
!ngrok config add-authtoken "34teOydZtLAfY5w9i8nyfjI5EGw_3WRUdcgKSLJTgMHdrAoUa" # Replace "YOUR_TOKEN_HERE" with your ngrok authtoken

# Start Streamlit app
!streamlit run app.py &>/dev/null&

# Create ngrok tunnel
public_url = ngrok.connect(8501)
print("ğŸš€ App running at:", public_url)