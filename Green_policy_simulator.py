# -*- coding: utf-8 -*-
"""Green Policy Simulator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nkHKQFGFHvHMKBV2pIIkJnwpfVx_0WIr
"""

# Install dependencies
!pip install streamlit pyngrok pandas numpy scikit-learn joblib plotly prophet -q

# Upload your dataset
from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv("ev_adoption_dataset_clean.csv")
df.head()

# Clean data and train model
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib, os

# Drop duplicates and fill missing
df = df.drop_duplicates()
df = df.fillna(df.median(numeric_only=True))
df = df.dropna()

# Encode categorical
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))

# Define target and features
target = "avg_cost_ev"   # adjust if your datasetâ€™s column name differs
X = df.drop(columns=[target])
y = df[target]

# Split, scale, and train
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)
y_pred = model.predict(X_test_scaled)

print("RÂ²:", r2_score(y_test, y_pred))
print("MAE:", mean_absolute_error(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

# Save model and scaler
os.makedirs("models", exist_ok=True)
joblib.dump(model, "models/ev_price_model.pkl")
joblib.dump(scaler, "models/scaler.pkl")

# Commented out IPython magic to ensure Python compatibility.
# # Create streamlit app
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import joblib
# 
# model = joblib.load("models/ev_price_model.pkl")
# scaler = joblib.load("models/scaler.pkl")
# 
# st.set_page_config(page_title="EV Price Predictor âš¡")
# 
# st.title("âš¡ Electric Vehicle Price Predictor")
# st.markdown("Enter the EV specifications below:")
# 
# battery = st.number_input("Battery Capacity (kWh)", 10.0, 200.0, 60.0)
# speed = st.number_input("Top Speed (km/h)", 50.0, 400.0, 180.0)
# range_km = st.number_input("Range (km)", 50.0, 800.0, 400.0)
# efficiency = st.number_input("Efficiency (Wh/km)", 100.0, 400.0, 180.0)
# seats = st.slider("Number of Seats", 2, 8, 5)
# 
# input_data = pd.DataFrame({
#     "battery": [battery],
#     "Top Speed": [speed],
#     "Range": [range_km],
#     "Efficiency": [efficiency],
#     "Seats": [seats]
# })
# 
# scaled = scaler.transform(input_data)
# if st.button("ğŸ”® Predict Price"):
#     pred = model.predict(scaled)[0]
#     st.success(f"Estimated Price: ${pred:,.2f}")
#     st.balloons()

# Run Streamlit through ngrok
!pip install pyngrok -q
from pyngrok import ngrok

# Replace the token below with your own from https://dashboard.ngrok.com/get-started/your-authtoken
!ngrok config add-authtoken "34teOydZtLAfY5w9i8nyfjI5EGw_3WRUdcgKSLJTgMHdrAoUa" # Replace "YOUR_TOKEN_HERE" with your ngrok authtoken

# Start Streamlit app
!streamlit run app.py &>/dev/null&

# Create ngrok tunnel
public_url = ngrok.connect(8501)
print("ğŸš€ App running at:", public_url)